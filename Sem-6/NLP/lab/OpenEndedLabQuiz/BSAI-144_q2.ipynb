{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf30fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Bi-grams:\n",
      "climate change: 2\n",
      "government announced: 1\n",
      "announced new: 1\n",
      "\n",
      "Top 2 Tri-grams:\n",
      "government announced new: 1\n",
      "announced new policies: 1\n",
      "\n",
      "Analysis:\n",
      "The most frequent meaningful phrases like 'climate change' and 'new policies' capture the key topics \n",
      "of the article. These n-grams can form the basis of a summary by highlighting the main subjects \n",
      "('climate change policies') and their effects ('impact industries significantly'). Filtering out stop \n",
      "words ensures we focus on content-bearing terms that truly represent the article's meaning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by tokenizing and cleaning punctuation\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove punctuation and single-character tokens\n",
    "    tokens = [token for token in tokens if token not in string.punctuation and len(token) > 1]\n",
    "    return tokens\n",
    "\n",
    "def generate_filtered_ngrams(tokens, n, stop_words):\n",
    "    \"\"\"Generate n-grams and filter out those containing stop words\"\"\"\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    # Filter n-grams that don't contain any stop words\n",
    "    filtered = [gram for gram in n_grams if not any(word in stop_words for word in gram)]\n",
    "    return filtered\n",
    "\n",
    "def analyze_ngrams(text):\n",
    "    \"\"\"Main function to analyze n-grams in text\"\"\"\n",
    "    # Download required NLTK resources if not already present\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "    # Get English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Preprocess text\n",
    "    tokens = preprocess_text(text)\n",
    "    \n",
    "    # Generate and filter bi-grams and tri-grams\n",
    "    bigrams = generate_filtered_ngrams(tokens, 2, stop_words)\n",
    "    trigrams = generate_filtered_ngrams(tokens, 3, stop_words)\n",
    "    \n",
    "    # Count frequencies\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    trigram_counts = Counter(trigrams)\n",
    "    \n",
    "    # Get top n-grams\n",
    "    top_bigrams = bigram_counts.most_common(3)\n",
    "    top_trigrams = trigram_counts.most_common(2)\n",
    "    \n",
    "    return top_bigrams, top_trigrams\n",
    "\n",
    "# Sample text\n",
    "text = \"The government announced new policies on climate change. Climate change policies will impact industries significantly. Industries must adapt to new regulations.\"\n",
    "\n",
    "# Perform analysis\n",
    "top_bigrams, top_trigrams = analyze_ngrams(text)\n",
    "\n",
    "# Display results\n",
    "print(\"Top 3 Bi-grams:\")\n",
    "for bigram, count in top_bigrams:\n",
    "    print(f\"{' '.join(bigram)}: {count}\")\n",
    "    \n",
    "print(\"\\nTop 2 Tri-grams:\")\n",
    "for trigram, count in top_trigrams:\n",
    "    print(f\"{' '.join(trigram)}: {count}\")\n",
    "\n",
    "# Analysis explanation\n",
    "analysis = \"\"\"\n",
    "Analysis:\n",
    "The most frequent meaningful phrases like 'climate change' and 'new policies' capture the key topics \n",
    "of the article. These n-grams can form the basis of a summary by highlighting the main subjects \n",
    "('climate change policies') and their effects ('impact industries significantly'). Filtering out stop \n",
    "words ensures we focus on content-bearing terms that truly represent the article's meaning.\n",
    "\"\"\"\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
