{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adeel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Adeel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "\n",
    "---\n",
    "\n",
    "The dataset used contains customer reviews from a womenâ€™s clothing e-commerce platform. It includes various columns such as Review Text, Rating, Age, and Clothing ID. For this task, the primary focus was on the **Review Text** column, which holds customer feedback about different clothing products. These reviews were used to perform natural language processing tasks like One Hot Encoding and Bag of Words, helping to convert the text data into numerical form for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\Adeel\\Desktop\\NLP\\Womens Clothing E-Commerce Reviews.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing\n",
    "---\n",
    "Preprocessing is an essential step in natural language processing that helps clean and standardize text data. In this case, the text from customer reviews was converted to lowercase to avoid treating words like \"Great\" and \"great\" differently. Punctuation was removed to focus only on meaningful words. The text was then split into individual words (tokens), and common stopwords like \"the\", \"and\", \"is\" were removed to reduce noise. This cleaned version of the text helps improve the performance of models like One Hot Encoding and Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a sample of non-null review texts\n",
    "sample_reviews = data['Review Text'].dropna().sample(10, random_state=1).tolist()\n",
    "\n",
    "custom_stopwords= set(stopwords.words('english')) \n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    tokens = text.split()\n",
    "    return [word for word in tokens if word not in custom_stopwords]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ðŸ”¹ **Task 1: One Hot Encoding**\n",
    "---\n",
    "\n",
    "**What was the task?**  \n",
    "The goal was to implement **One Hot Encoding** for a dataset of consumer reviews on clothing products. Each word in the review text had to be represented as a binary vector indicating its presence in a sentence.\n",
    "\n",
    "**How did you do that?**  \n",
    "- First, we randomly selected 10 reviews from the dataset and removed null values.\n",
    "- Each review was **preprocessed**: converted to lowercase, punctuation removed, and stopwords filtered out.\n",
    "- A **vocabulary** of unique words was created from the cleaned text.\n",
    "- For each review, we generated a binary vector where each index represents a word from the vocabulary. If the word exists in the review, that index is marked `1`; otherwise, `0`.\n",
    "\n",
    "**Library functions used:**  \n",
    "- `pandas` for data loading and manipulation  \n",
    "- `numpy` for array and vector operations  \n",
    "- `re` (regular expressions) for punctuation removal  \n",
    "- `time` to measure execution time  \n",
    "- `sk-learn` for one hot-encoding\n",
    "\n",
    "**What are the results?**  \n",
    "- The one-hot encoded matrix has a shape of `(10, N)`, where 10 is the number of reviews and `N` is the number of unique words (vocabulary size).\n",
    "- Each row in the matrix represents the word presence (1 or 0) for a given review.\n",
    "\n",
    "**Execution Time:**  \n",
    "Approximately **X.XXX seconds** (replace with actual value from your run).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: One Hot Encoding\n",
      "Vocabulary Size: 256\n",
      "One Hot Matrix Shape: (10, 256)\n",
      "One Hot Matrix:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Execution Time: 0.006 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time_1hot = time.time()\n",
    "\n",
    "# Preprocess and create vocabulary\n",
    "processed_reviews = [preprocess(review) for review in sample_reviews]\n",
    "vocab = sorted(set(word for review in processed_reviews for word in review))\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# One-hot encode each review\n",
    "def one_hot_encode(tokens, vocab):\n",
    "    vector = np.zeros(len(vocab), dtype=int)\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            vector[word2idx[token]] = 1\n",
    "    return vector\n",
    "\n",
    "one_hot_matrix = np.array([one_hot_encode(review, vocab) for review in processed_reviews])\n",
    "\n",
    "end_time_1hot = time.time()\n",
    "\n",
    "print(\"Task 1: One Hot Encoding\")\n",
    "print(\"Vocabulary Size:\", len(vocab))\n",
    "print(\"One Hot Matrix Shape:\", one_hot_matrix.shape)\n",
    "print(\"One Hot Matrix:\\n\", one_hot_matrix)\n",
    "print(\"Execution Time:\", round(end_time_1hot - start_time_1hot, 4), \"seconds\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ **Task 2: Bag of Words (BoW)**\n",
    "---\n",
    "**What was the task?**  \n",
    "The objective was to implement a **Bag of Words** model for customer feedback. We needed to count how frequently each word appears in each review.\n",
    "\n",
    "**How did you do that?**  \n",
    "- We used the same preprocessed text from Task 1.\n",
    "- Each cleaned review was converted back to a string (from token list).\n",
    "- We used `CountVectorizer` from `sklearn` to build the BoW matrix.\n",
    "- The matrix counts how many times each word from the vocabulary appears in each review.\n",
    "\n",
    "**Library functions used:**  \n",
    "- `CountVectorizer` from `sklearn.feature_extraction.text`  \n",
    "- `pandas`, `numpy`, `re` as before  \n",
    "- `time` to measure execution time  \n",
    "\n",
    "**What are the results?**  \n",
    "- The resulting matrix shape is `(10, M)`, where 10 is the number of reviews and `M` is the number of unique words used across all reviews.\n",
    "- Each cell in the matrix shows how many times a word appears in a specific review.\n",
    "\n",
    "**Execution Time:**  \n",
    "Approximately **Y.YYY seconds** (replace with actual value from your run).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: Bag of Words\n",
      "BoW Matrix Shape: (10, 255)\n",
      "   102  135lbs  32e  40  52  54  628  absolutely  according  actually  ...  \\\n",
      "0    0       0    0   0   0   0    0           0          0         0  ...   \n",
      "1    1       0    0   0   1   0    0           0          0         0  ...   \n",
      "2    0       1    1   0   0   1    0           1          0         0  ...   \n",
      "3    0       0    0   0   0   0    0           0          0         0  ...   \n",
      "4    0       0    0   0   0   0    0           0          1         0  ...   \n",
      "\n",
      "   worth  would  wouldnt  xl  xs  xxs  yay  yeah  years  zipper  \n",
      "0      0      0        0   0   0    0    0     0      0       0  \n",
      "1      0      0        0   0   1    2    0     0      0       0  \n",
      "2      0      0        0   0   0    0    0     0      0       0  \n",
      "3      0      0        0   0   0    0    1     0      0       0  \n",
      "4      0      0        0   0   0    0    0     0      0       0  \n",
      "\n",
      "[5 rows x 255 columns]\n",
      "Execution Time: 0.0081 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time_bow = time.time()\n",
    "\n",
    "# Re-join processed tokens to string for CountVectorizer\n",
    "cleaned_strings = [\" \".join(review) for review in processed_reviews]\n",
    "\n",
    "# Apply CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(cleaned_strings).toarray()\n",
    "bow_df = pd.DataFrame(bow_matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "end_time_bow = time.time()\n",
    "\n",
    "print(\"Task 2: Bag of Words\")\n",
    "print(\"BoW Matrix Shape:\", bow_df.shape)\n",
    "print(bow_df.head())\n",
    "print(\"Execution Time:\", round(end_time_bow - start_time_bow, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------The End-----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
