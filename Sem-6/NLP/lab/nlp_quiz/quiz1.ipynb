{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lfSN2I8HpY3a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "pg = \"\"\"Natural Language Processing (NLP) is a fascinating field of artificial intelligence that focuses on\n",
        "the interaction between humans and computers using natural language. It involves various\n",
        "techniques such as tokenization, stemming, lemmatization, and semantic analysis to process and\n",
        "analyze textual data. For example, removing stopwords like 'the' and 'is' can help reduce noise in\n",
        "the text, while tasks like named entity recognition (NER) identify important entities such as\n",
        "'Google' or 'New York.' Dependency parsing further reveals the grammatical structure of sentences,\n",
        "enabling deeper insights into relationships between words. NLP techniques are widely applied in\n",
        "applications like chatbots, sentiment analysis, and machine translation. For instance, a chatbot\n",
        "might process 1,000 user queries per day, while sentiment analysis can classify text into categories\n",
        "like positive (e.g., +1), neutral (0), or negative (-1). Additionally, machine translation systems can\n",
        "translate up to 10 million words daily across multiple languages.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize the paragraph into words and remove punctuation marks.**"
      ],
      "metadata": {
        "id": "-ssnrvTQppWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E0oL0hmqqOF",
        "outputId": "22c67922-c1da-448d-c2f6-b7599e84b66c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "tokens = word_tokenize(pg)\n",
        "tokens_without_punctuation = [word for word in tokens if word not in string.punctuation]\n",
        "print(\"TOKENIZE WORDS \\n\",tokens_without_punctuation)\n",
        "cleaned_text = ' '.join(tokens_without_punctuation)\n",
        "print(\"CLEAN PARAGRAPH \\n\",cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsy6O_ypb1e",
        "outputId": "7e7fb780-5462-48d3-f678-4870ef589636"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKENIZE WORDS \n",
            " ['Natural', 'Language', 'Processing', 'NLP', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'humans', 'and', 'computers', 'using', 'natural', 'language', 'It', 'involves', 'various', 'techniques', 'such', 'as', 'tokenization', 'stemming', 'lemmatization', 'and', 'semantic', 'analysis', 'to', 'process', 'and', 'analyze', 'textual', 'data', 'For', 'example', 'removing', 'stopwords', 'like', \"'the\", 'and', \"'is\", 'can', 'help', 'reduce', 'noise', 'in', 'the', 'text', 'while', 'tasks', 'like', 'named', 'entity', 'recognition', 'NER', 'identify', 'important', 'entities', 'such', 'as', \"'Google\", 'or', \"'New\", 'York', 'Dependency', 'parsing', 'further', 'reveals', 'the', 'grammatical', 'structure', 'of', 'sentences', 'enabling', 'deeper', 'insights', 'into', 'relationships', 'between', 'words', 'NLP', 'techniques', 'are', 'widely', 'applied', 'in', 'applications', 'like', 'chatbots', 'sentiment', 'analysis', 'and', 'machine', 'translation', 'For', 'instance', 'a', 'chatbot', 'might', 'process', '1,000', 'user', 'queries', 'per', 'day', 'while', 'sentiment', 'analysis', 'can', 'classify', 'text', 'into', 'categories', 'like', 'positive', 'e.g.', '+1', 'neutral', '0', 'or', 'negative', '-1', 'Additionally', 'machine', 'translation', 'systems', 'can', 'translate', 'up', 'to', '10', 'million', 'words', 'daily', 'across', 'multiple', 'languages']\n",
            "CLEAN PARAGRAPH \n",
            " Natural Language Processing NLP is a fascinating field of artificial intelligence that focuses on the interaction between humans and computers using natural language It involves various techniques such as tokenization stemming lemmatization and semantic analysis to process and analyze textual data For example removing stopwords like 'the and 'is can help reduce noise in the text while tasks like named entity recognition NER identify important entities such as 'Google or 'New York Dependency parsing further reveals the grammatical structure of sentences enabling deeper insights into relationships between words NLP techniques are widely applied in applications like chatbots sentiment analysis and machine translation For instance a chatbot might process 1,000 user queries per day while sentiment analysis can classify text into categories like positive e.g. +1 neutral 0 or negative -1 Additionally machine translation systems can translate up to 10 million words daily across multiple languages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function to filter out numbers and special characters.**"
      ],
      "metadata": {
        "id": "UogrcK1GrzWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def filter_non_alphabetic(text):\n",
        "  filtered_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  return filtered_text\n",
        "text = \"Remove #special characters from this text!\"\n",
        "filtered_text = filter_non_alphabetic(pg)\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j9tCbBaqB_u",
        "outputId": "f6a664b6-7bf1-49c1-e7e0-bbb1ca930826"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing NLP is a fascinating field of artificial intelligence that focuses on \n",
            "the interaction between humans and computers using natural language It involves various \n",
            "techniques such as tokenization stemming lemmatization and semantic analysis to process and \n",
            "analyze textual data For example removing stopwords like the and is can help reduce noise in \n",
            "the text while tasks like named entity recognition NER identify important entities such as \n",
            "Google or New York Dependency parsing further reveals the grammatical structure of sentences \n",
            "enabling deeper insights into relationships between words NLP techniques are widely applied in \n",
            "applications like chatbots sentiment analysis and machine translation For instance a chatbot \n",
            "might process  user queries per day while sentiment analysis can classify text into categories \n",
            "like positive eg  neutral  or negative  Additionally machine translation systems can \n",
            "translate up to  million words daily across multiple languages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validate if the given text contains profanity using profanity-check.**"
      ],
      "metadata": {
        "id": "94YRDfq4sUp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install profanity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92F9ktisZhM",
        "outputId": "afa0ae2e-e768-4330-a78d-c9ac06ef0c1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting profanity\n",
            "  Downloading profanity-1.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: profanity\n",
            "  Building wheel for profanity (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for profanity: filename=profanity-1.1-py3-none-any.whl size=4228 sha256=9c447c8f68804744dcfaf19292b1c81c35a7c4ec84cf3f034ca51e93c985e4d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/73/58/1b54f97bf622e6d79c75b5ec4043b69e3bec1423c84de7a83f\n",
            "Successfully built profanity\n",
            "Installing collected packages: profanity\n",
            "Successfully installed profanity-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from profanity import profanity\n",
        "\n",
        "if profanity.contains_profanity(pg):\n",
        "    print(\"The text contains profanity.\")\n",
        "else:\n",
        "    print(\"The text is clean.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KY7ZSTntLXF",
        "outputId": "6688ca8a-9bb0-4651-ec25-ba5c4fa130c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text contains profanity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform stemming on a given text using the Porter Stemmer algorithm.**"
      ],
      "metadata": {
        "id": "ger3QWOGt0EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "def stem_text(text):\n",
        "  stemmer = PorterStemmer()\n",
        "  words = word_tokenize(text)\n",
        "  stemmed_words = [stemmer.stem(word) for word in words]\n",
        "  stemmed_text = ' '.join(stemmed_words)\n",
        "  return stemmed_text\n",
        "stemmed_text = stem_text(pg)\n",
        "print(stemmed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rWgzQX5ttot",
        "outputId": "7a41ae00-db37-44ad-af2b-fd585e10b29a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natur languag process ( nlp ) is a fascin field of artifici intellig that focus on the interact between human and comput use natur languag . it involv variou techniqu such as token , stem , lemmat , and semant analysi to process and analyz textual data . for exampl , remov stopword like 'the ' and 'i ' can help reduc nois in the text , while task like name entiti recognit ( ner ) identifi import entiti such as 'googl ' or 'new york . ' depend pars further reveal the grammat structur of sentenc , enabl deeper insight into relationship between word . nlp techniqu are wide appli in applic like chatbot , sentiment analysi , and machin translat . for instanc , a chatbot might process 1,000 user queri per day , while sentiment analysi can classifi text into categori like posit ( e.g. , +1 ) , neutral ( 0 ) , or neg ( -1 ) . addit , machin translat system can translat up to 10 million word daili across multipl languag .\n"
          ]
        }
      ]
    }
  ]
}